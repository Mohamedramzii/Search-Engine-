{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from nltk.util import pr\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from natsort import natsorted\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from yaml.tokens import Token\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "path = r\"C:/Users/Yousef Khaled/Documents/GitHub/Information_retrival/New folder\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert paths in dataset \n",
    "stemmer= PorterStemmer()\n",
    "File_Map=[]\n",
    "pos_index = {}\n",
    "file_map={}\n",
    "for file in os.listdir():\n",
    "\n",
    "    if file.endswith(\".txt\"):\n",
    "        file_path = f\"{path}/{file}\"\n",
    "        File_Map.append(file_path)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/Yousef Khaled/Documents/GitHub/Information_retrival/New folder/1.txt',\n",
       " 'C:/Users/Yousef Khaled/Documents/GitHub/Information_retrival/New folder/2.txt',\n",
       " 'C:/Users/Yousef Khaled/Documents/GitHub/Information_retrival/New folder/3.txt',\n",
       " 'C:/Users/Yousef Khaled/Documents/GitHub/Information_retrival/New folder/4.txt',\n",
       " 'C:/Users/Yousef Khaled/Documents/GitHub/Information_retrival/New folder/5.txt',\n",
       " 'C:/Users/Yousef Khaled/Documents/GitHub/Information_retrival/New folder/6.txt',\n",
       " 'C:/Users/Yousef Khaled/Documents/GitHub/Information_retrival/New folder/7.txt',\n",
       " 'C:/Users/Yousef Khaled/Documents/GitHub/Information_retrival/New folder/8.txt']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "File_Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of documents used\n",
    "N=len(File_Map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lower_case(data):\n",
    "    return np.char.lower(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(data):\n",
    "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    for i in range(len(symbols)):\n",
    "        data = np.char.replace(data, symbols[i], ' ')\n",
    "        data = np.char.replace(data, \"  \", \" \")\n",
    "    data = np.char.replace(data, ',', '')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_apostrophe(data):\n",
    "    return np.char.replace(data, \"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(data):\n",
    "    stop_words = stopwords.words('english')\n",
    "    words = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in words:\n",
    "        if w not in stop_words and len(w) > 1:\n",
    "            new_text = new_text + \" \" + w\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stemming(data):\n",
    "#     tokens = word_tokenize(str(data))\n",
    "#     new_text = \"\"\n",
    "#     for w in tokens:\n",
    "#         new_text = new_text + \" \" + stemmer.stem(w)\n",
    "#     return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    data = convert_lower_case(data)\n",
    "    data = remove_punctuation(data) \n",
    "    data = remove_apostrophe(data)\n",
    "    data = remove_stop_words(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file from pathes in dataset and extract terms after prepocessing\n",
    "processed_text = []\n",
    "\n",
    "for i in File_Map:\n",
    "    file = open(i, 'r', encoding=\"utf8\", errors='ignore')\n",
    "    text = file.read().strip()\n",
    "    file.close()\n",
    "\n",
    "    processed_text.append(word_tokenize(str(preprocess(text))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['president', 'talks', 'uconn'],\n",
       " ['apple', 'stock', 'hot'],\n",
       " ['born', 'ideals', 'dreams'],\n",
       " ['born', 'greatness'],\n",
       " ['born', 'wings'],\n",
       " ['meant', 'crawling', 'dont'],\n",
       " ['wings'],\n",
       " ['learn', 'use', 'fly']]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_index():\n",
    "    fileno = 0\n",
    "    i=0\n",
    "    for file_name in File_Map:\n",
    "            \n",
    "            text = processed_text[i]\n",
    "            #print(text)\n",
    "\n",
    "            for pos, term in enumerate(text):\n",
    "                #term = stemmer.stem(term)\n",
    "\n",
    "                if term in pos_index:\n",
    "                    pos_index[term][0] = pos_index[term][0] + 1\n",
    "\n",
    "                    if fileno in pos_index[term][1]:\n",
    "                        pos_index[term][1][fileno].append(pos)\n",
    "\n",
    "                    else:\n",
    "                        pos_index[term][1][fileno] = [pos]\n",
    "\n",
    "                else:\n",
    "                    pos_index[term] = []\n",
    "                    pos_index[term].append(1)\n",
    "                    pos_index[term].append({})\n",
    "                    pos_index[term][1][fileno] = [pos]\n",
    "                \n",
    "            i=i+1\t\t\n",
    "            file_map[fileno] = File_Map[fileno]\n",
    "            fileno += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " please write phrase query on positional index \n",
      " born\n",
      "this word does't exist \n"
     ]
    }
   ],
   "source": [
    "input_user = input(\"\\n please write phrase query on positional index \\n \")  \n",
    "\n",
    "try:\n",
    "    sample_pos_idx = pos_index[input_user]\n",
    "    print(\"\\n Positional Index\")\n",
    "    print(sample_pos_idx)\n",
    "\n",
    "    file_list = sample_pos_idx[1]\n",
    "\n",
    "    print(\"\\n Filename, \\t [Positions] \\n \")\n",
    "    for fileno, positions in file_list.items():\n",
    "        print(file_map[fileno] , positions)\n",
    "        print(\"\\n\")\n",
    "except KeyError:\n",
    "    print(\"this word does't exist \")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = {}\n",
    "\n",
    "for i in range(N):\n",
    "    tokens = processed_text[i]\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            DF[w].add(i)\n",
    "        except:\n",
    "            DF[w] = {i}\n",
    "\n",
    "for i in DF:\n",
    "    DF[i] = len(DF[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'president': 1,\n",
       " 'talks': 1,\n",
       " 'uconn': 1,\n",
       " 'apple': 1,\n",
       " 'stock': 1,\n",
       " 'hot': 2,\n",
       " 'job': 1,\n",
       " 'market': 1}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_f(word):\n",
    "    doc_number = 0\n",
    "    try:\n",
    "        c = DF[word]\n",
    "    except:\n",
    "        pass\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate  Term Frequency and IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "president in document 1 : term frequence is  :  0.3333333333333333\n",
      " IDF is : 1.0986122886681098\n",
      "1\n",
      "talks in document 1 : term frequence is  :  0.3333333333333333\n",
      " IDF is : 1.0986122886681098\n",
      "1\n",
      "uconn in document 1 : term frequence is  :  0.3333333333333333\n",
      " IDF is : 1.0986122886681098\n",
      "1\n",
      "apple in document 2 : term frequence is  :  0.3333333333333333\n",
      " IDF is : 1.0986122886681098\n",
      "2\n",
      "hot in document 2 : term frequence is  :  0.3333333333333333\n",
      " IDF is : 0.4054651081081644\n",
      "1\n",
      "stock in document 2 : term frequence is  :  0.3333333333333333\n",
      " IDF is : 1.0986122886681098\n",
      "2\n",
      "hot in document 3 : term frequence is  :  0.5\n",
      " IDF is : 0.4054651081081644\n",
      "1\n",
      "job in document 3 : term frequence is  :  0.25\n",
      " IDF is : 1.0986122886681098\n",
      "1\n",
      "market in document 3 : term frequence is  :  0.25\n",
      " IDF is : 1.0986122886681098\n"
     ]
    }
   ],
   "source": [
    "doc = 0\n",
    "\n",
    "tf_idf = {}\n",
    "\n",
    "for i in range(N):\n",
    "    \n",
    "    tokens = processed_text[i]\n",
    "    \n",
    "    counter = Counter(tokens )\n",
    "    words_count = len(tokens )\n",
    "    \n",
    "    for token in np.unique(tokens):\n",
    "        \n",
    "        tf = counter[token]/words_count\n",
    "        \n",
    "        df = document_f(token)\n",
    "        print(df)\n",
    "        idf = np.log(N/(df))\n",
    "        print(token+' in document '+str(doc+1)+' : term frequence is  :  '+str(tf)+'\\n IDF is : ' +str(idf))\n",
    "        tf_idf[doc, token] = tf*idf\n",
    "\n",
    "    doc += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display tf.IDF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=list(tf_idf.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list=[]\n",
    "term_list=[]\n",
    "for i in range(len(x)):\n",
    "    doc_list.append(x[i][0])\n",
    "    term_list.append(x[i][1])\n",
    "term_list=np.unique(term_list) \n",
    "doc_list=np.unique(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "columns=[]\n",
    "columns.append('term')\n",
    "for i in doc_list:\n",
    "    columns.append('doc'+str(i+1))\n",
    "    \n",
    "TF_ID_matrix=pd.DataFrame(columns=columns,index=None)\n",
    "TF_ID_matrix['term']=term_list\n",
    "for i in range(len(TF_ID_matrix)):\n",
    "    for j in doc_list:\n",
    "        first_key=j\n",
    "        column='doc'+str(j+1)\n",
    "        second_key=TF_ID_matrix['term'].iloc[i]\n",
    "        if(first_key, second_key)in tf_idf.keys():\n",
    "            TF_ID_matrix[column].iloc[i]=tf_idf[first_key,second_key]\n",
    "        else:\n",
    "            continue\n",
    "TF_ID_matrix.fillna(0,inplace=True)            \n",
    "\n",
    "TF_ID_matrix.to_csv('TF_ID_matrix.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>doc1</th>\n",
       "      <th>doc2</th>\n",
       "      <th>doc3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>apple</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.159040</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>hot</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.058697</td>\n",
       "      <td>0.088046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>job</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>market</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>president</td>\n",
       "      <td>0.15904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>stock</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.159040</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>talks</td>\n",
       "      <td>0.15904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>uconn</td>\n",
       "      <td>0.15904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term     doc1      doc2      doc3\n",
       "0      apple  0.00000  0.159040  0.000000\n",
       "1        hot  0.00000  0.058697  0.088046\n",
       "2        job  0.00000  0.000000  0.119280\n",
       "3     market  0.00000  0.000000  0.119280\n",
       "4  president  0.15904  0.000000  0.000000\n",
       "5      stock  0.00000  0.159040  0.000000\n",
       "6      talks  0.15904  0.000000  0.000000\n",
       "7      uconn  0.15904  0.000000  0.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF_ID_matrix.head(20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
